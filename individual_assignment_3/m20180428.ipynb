{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Utils\n",
    "\n",
    "# def run_kfold(clf, X, y):\n",
    "#     nfolds = 1000    \n",
    "#     sss = StratifiedShuffleSplit(n_splits=nfolds, test_size=0.25, random_state=2020)\n",
    "#     mean_outcome = 0\n",
    "    \n",
    "#     for train_indices, test_indices in sss.split(X, y):\n",
    "#         X_train, X_test = X.values[train_indices], X.values[test_indices]\n",
    "#         y_train, y_test = y.values[train_indices], y.values[test_indices]\n",
    "#         clf.fit(X_train, y_train)\n",
    "#         predictions = clf.predict(X_test)\n",
    "#         f1 = f1_score(y_test, predictions, average=\"micro\")\n",
    "#         mean_outcome += f1\n",
    "\n",
    "#     mean_outcome /= nfolds\n",
    "#     print(f\"\\t...mean F1-Score: {mean_outcome}\")\n",
    "    \n",
    "#     return mean_outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"./data\"\n",
    "output_folder = \"./results\"\n",
    "profiles_folder = \"./profiles\"\n",
    "train = pd.read_csv(f\"{input_folder}/train.csv\")\n",
    "test = pd.read_csv(f\"{input_folder}/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Churn_risk\"\n",
    "train[\"is_train\"] = 1\n",
    "y = train[target]\n",
    "test[\"is_train\"] = 0\n",
    "alldata = pd.concat([train.drop(target, axis=1), test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in [\"Department\", \"Gender\", \"Marital_status\"]:\n",
    "    alldata = pd.concat([alldata.drop(column, axis=1), pd.get_dummies(alldata[column], prefix=column.split(\"_\")[0])], axis=1)\n",
    "\n",
    "train = alldata[alldata[\"is_train\"]==1].drop(\"is_train\", axis=1)\n",
    "test  = alldata[alldata[\"is_train\"]==0].drop(\"is_train\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_risk_dict = {\"low\": 0, \"medium\": 1, \"high\": 2}\n",
    "reverse_churn_risk_dict = {value: key for key, value in churn_risk_dict.items()}\n",
    "\n",
    "X = train.drop([\"Employee_ID\"], axis=1)\n",
    "y = y.map(churn_risk_dict).astype(np.int8)\n",
    "\n",
    "train_cols = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X.fillna(X.mean()), columns=train_cols)\n",
    "\n",
    "test_ids = test[\"Employee_ID\"]\n",
    "test = pd.DataFrame(test.fillna(test.mean()), columns=train_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the DT model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "#                            max_depth=13, max_features=0.9, max_leaf_nodes=None,\n",
    "#                            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#                            min_samples_leaf=1, min_samples_split=2,\n",
    "#                            min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "#                            random_state=2020, splitter='best')\n",
    "\n",
    "clf = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                       max_depth=15, max_features=0.7, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                       random_state=2020, splitter='best')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\t...mean F1-Score: 0.7154492307692301"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# nfolds = 1000\n",
    "# sss = StratifiedShuffleSplit(n_splits=nfolds, test_size=0.25, random_state=2020)\n",
    "\n",
    "# selector = RFECV(clf, step=1, cv=sss, scoring=\"f1_micro\")\n",
    "# selector = selector.fit(X, y)\n",
    "# print(\"selector\", selector)\n",
    "# print(\"selector.support_\", selector.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# best_cols = X.columns[selector.support_]\n",
    "# best_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cols = ['Age', 'Days_off', 'Satis_leader', 'Satis_team', 'Emails', 'Tenure', 'Bonus', 'Distance', 'Kids', 'Overtime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = run_kfold(clf, X[best_cols], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# clf = DecisionTreeClassifier(random_state=2020)\n",
    "\n",
    "# # Choose some parameter combinations to try\n",
    "# parameters = {\n",
    "#     \"criterion\": [\"gini\", \"entropy\"],\n",
    "#     \"class_weight\": [None, \"balanced\"],\n",
    "#     \"max_features\": [\"sqrt\", \"log2\", 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "#     \"splitter\": [\"best\", \"random\"],\n",
    "#     \"max_depth\": [None, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "# }\n",
    "\n",
    "# # Run the grid search\n",
    "# grid_obj = GridSearchCV(clf, parameters, scoring=\"f1_micro\", cv=5, verbose=2, refit=True, n_jobs=-1)\n",
    "# grid_obj.fit(X[best_cols], y)\n",
    "\n",
    "# # Set the clf to the best combination of parameters\n",
    "# clf = grid_obj.best_estimator_\n",
    "# clf_params = grid_obj.best_params_\n",
    "# clf_score = grid_obj.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# run_kfold(clf, X[best_cols], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=15, max_features=0.7, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=2020, splitter='best')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X[best_cols], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(test[best_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Writing Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reversing `Churn_risk` encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.Series(preds).map(reverse_churn_risk_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lazy get submission version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_version():\n",
    "    \"\"\"\n",
    "    Finds automatically the version of the submission. :)\n",
    "    \"\"\"\n",
    "    version = 1\n",
    "    if len(os.listdir(\"results\")) > 0:\n",
    "        for file in os.listdir(\"results\"):\n",
    "            if file.split(\"_\")[1].startswith(\"version\"):\n",
    "                if int(file.split(\"_\")[1].split(\"n\")[1].split(\".\")[0]) > version:\n",
    "                    version = int(file.split(\"_\")[1].split(\"n\")[1].split(\".\")[0])\n",
    "        return version + 1\n",
    "    else:\n",
    "        return version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee_ID</th>\n",
       "      <th>Churn_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1005201</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1005202</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005203</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1005204</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005205</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Employee_ID Churn_risk\n",
       "0      1005201        low\n",
       "1      1005202     medium\n",
       "2      1005203     medium\n",
       "3      1005204        low\n",
       "4      1005205     medium"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame({\"Employee_ID\": test_ids, \"Churn_risk\": preds})\n",
    "output.to_csv(f'{output_folder}/m20180428_version{find_version()}.csv', index = False)\n",
    "output.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (machine_learning)",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
