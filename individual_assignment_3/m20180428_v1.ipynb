{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "\n",
    "def run_kfold(clf, X, y):\n",
    "    nfolds = 1000    \n",
    "    sss = StratifiedShuffleSplit(n_splits=nfolds, test_size=0.25, random_state=2020)\n",
    "    mean_outcome = 0\n",
    "    \n",
    "    for train_indices, test_indices in sss.split(X, y):\n",
    "        X_train, X_test = X.values[train_indices], X.values[test_indices]\n",
    "        y_train, y_test = y.values[train_indices], y.values[test_indices]\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        f1 = f1_score(y_test, predictions, average=\"micro\")\n",
    "        mean_outcome += f1\n",
    "\n",
    "    mean_outcome /= nfolds\n",
    "    print(f\"\\t...mean F1-Score: {mean_outcome}\")\n",
    "    \n",
    "    return mean_outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"./data\"\n",
    "output_folder = \"./results\"\n",
    "profiles_folder = \"./profiles\"\n",
    "train = pd.read_csv(f\"{input_folder}/train.csv\")\n",
    "test = pd.read_csv(f\"{input_folder}/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Churn_risk\"\n",
    "train[\"is_train\"] = 1\n",
    "y = train[target]\n",
    "test[\"is_train\"] = 0\n",
    "alldata = pd.concat([train.drop(target, axis=1), test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in [\"Department\", \"Gender\", \"Marital_status\"]:\n",
    "    alldata = pd.concat([alldata.drop(column, axis=1), pd.get_dummies(alldata[column], prefix=column.split(\"_\")[0])], axis=1)\n",
    "\n",
    "train = alldata[alldata[\"is_train\"]==1].drop(\"is_train\", axis=1)\n",
    "test  = alldata[alldata[\"is_train\"]==0].drop(\"is_train\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_risk_dict = {\"low\": 0, \"medium\": 1, \"high\": 2}\n",
    "reverse_churn_risk_dict = {value: key for key, value in churn_risk_dict.items()}\n",
    "\n",
    "X = train.drop([\"Employee_ID\"], axis=1)\n",
    "y = y.map(churn_risk_dict).astype(np.int8)\n",
    "\n",
    "train_cols = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute = \"mean\"\n",
    "\n",
    "if impute == \"KNN\":\n",
    "    imputer = KNNImputer()\n",
    "    X = pd.DataFrame(imputer.fit_transform(X), columns=train_cols)\n",
    "else:\n",
    "    X = pd.DataFrame(X.fillna(X.mean()), columns=train_cols)\n",
    "\n",
    "test_ids = test[\"Employee_ID\"]\n",
    "\n",
    "if impute == \"KNN\":\n",
    "    test = pd.DataFrame(imputer.transform(test.drop(\"Employee_ID\", axis=1)), columns=train_cols)\n",
    "else:\n",
    "    test = pd.DataFrame(test.fillna(test.mean()), columns=train_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the DT model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(\n",
    "    random_state=2020,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=10,\n",
    "    max_features=0.7,\n",
    "    splitter=\"best\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10...\n",
      "20...\n",
      "30...\n",
      "40...\n",
      "50...\n",
      "60...\n",
      "70...\n",
      "80...\n",
      "90...\n",
      "100...\n",
      "110...\n",
      "120...\n",
      "130...\n",
      "140...\n",
      "150...\n",
      "160...\n",
      "170...\n",
      "180...\n",
      "190...\n",
      "200...\n",
      "210...\n",
      "220...\n",
      "230...\n",
      "240...\n",
      "250...\n",
      "260...\n",
      "270...\n",
      "277 total combinations\n",
      "best combination: ('Age', 'Days_off', 'Rotations', 'Satis_leader', 'Satis_team', 'Emails', 'Tenure', 'Bonus', 'Distance', 'Kids', 'Overtime', 'Department_accounting', 'Department_finances', 'Department_human resources', 'Department_sales', 'Gender_female', 'Gender_male', 'Marital_married', 'Marital_single', 'Marital_together', 'Marital_widow')\n",
      "Wall time: 1h 22min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "nfolds = 1000\n",
    "sss = StratifiedShuffleSplit(n_splits=nfolds, test_size=0.25, random_state=2020)\n",
    "total_combs = 0\n",
    "best_score, best_combo = -1, []\n",
    "\n",
    "Xraw = X.copy()\n",
    "\n",
    "for length in [len(train_cols)-2, len(train_cols)-1, len(train_cols)]:\n",
    "    for combo in itertools.combinations(train_cols, length):\n",
    "        total_combs += 1\n",
    "        if total_combs % 10 == 0: print(f\"{total_combs}...\")\n",
    "        mean_outcome = 0\n",
    "        \n",
    "        for train_indices, test_indices in sss.split(X, y):\n",
    "            X_train, X_test = X[list(combo)].values[train_indices], X[list(combo)].values[test_indices]\n",
    "            y_train, y_test = y.values[train_indices], y.values[test_indices]\n",
    "            \n",
    "            clf.fit(X_train, y_train)\n",
    "            predictions = clf.predict(X_test)\n",
    "            f1 = f1_score(y_test, predictions, average=\"micro\")\n",
    "            mean_outcome += f1\n",
    "\n",
    "        mean_outcome /= nfolds        \n",
    "        \n",
    "        if mean_outcome > best_score:\n",
    "            best_score = mean_outcome\n",
    "            best_combo = combo\n",
    "            \n",
    "print(f\"{total_combs} total combinations\")\n",
    "print(f\"best combination: {best_combo}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best combination: ('Age', 'Days_off', 'Rotations', 'Satis_leader', 'Satis_team', 'Emails', 'Tenure', 'Bonus', 'Distance', 'Kids', 'Overtime', 'Department_accounting', 'Department_finances', 'Department_human resources', 'Department_sales', 'Gender_female', 'Gender_male', 'Marital_married', 'Marital_single', 'Marital_together', 'Marital_widow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_combo = list(best_combo)\n",
    "len(best_combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Folds: 1000\n",
      "\t...mean F1-Score: 0.7058861538461554\n"
     ]
    }
   ],
   "source": [
    "score = run_kfold(clf, X[list(best_combo)], y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\t...mean F1-Score: 0.7058861538461554"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1080 candidates, totalling 5400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 5400 out of 5400 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=2020)\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "parameters = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"class_weight\": [None, \"balanced\"],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    \"splitter\": [\"best\", \"random\"],\n",
    "    \"max_depth\": [None, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "}\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=\"f1_micro\", cv=5, verbose=1, refit=True)\n",
    "grid_obj.fit(X[best_combo], y)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "clf = grid_obj.best_estimator_\n",
    "clf_params = grid_obj.best_params_\n",
    "clf_score = grid_obj.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 14,\n",
       " 'max_features': 0.7,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Folds: 1000\n",
      "\t...mean F1-Score: 0.714363846153846\n",
      "Wall time: 19.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.714363846153846"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "run_kfold(clf, X[best_combo], y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\t...mean F1-Score: 0.714363846153846"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=14, max_features=0.7, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=2020, splitter='best')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X[best_combo], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = clf.predict(test)\n",
    "preds = clf.predict(test[best_combo])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Writing Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reversing `Churn_risk` encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.Series(preds).map(reverse_churn_risk_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lazy get submission version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_version():\n",
    "    \"\"\"\n",
    "    Finds automatically the version of the submission. :)\n",
    "    \"\"\"\n",
    "    version = 1\n",
    "    if len(os.listdir(\"results\")) > 0:\n",
    "        for file in os.listdir(\"results\"):\n",
    "            if file.split(\"_\")[1].startswith(\"version\"):\n",
    "                if int(file.split(\"_\")[1].split(\"n\")[1].split(\".\")[0]) > version:\n",
    "                    version = int(file.split(\"_\")[1].split(\"n\")[1].split(\".\")[0])\n",
    "        return version + 1\n",
    "    else:\n",
    "        return version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee_ID</th>\n",
       "      <th>Churn_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1005201</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1005202</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005203</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1005204</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005205</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Employee_ID Churn_risk\n",
       "0      1005201        low\n",
       "1      1005202     medium\n",
       "2      1005203     medium\n",
       "3      1005204     medium\n",
       "4      1005205     medium"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame({\"Employee_ID\": test_ids, \"Churn_risk\": preds})\n",
    "output.to_csv(f'{output_folder}/m20180428_version{find_version()}.csv', index = False)\n",
    "output.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (machine_learning)",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
